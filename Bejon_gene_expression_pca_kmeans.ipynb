{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3249,
          "sourceType": "datasetVersion",
          "datasetId": 1868
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bejon23/Apr19_Saimon_Heart_Disease_Pred/blob/main/Bejon_gene_expression_pca_kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1868%2F3249%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240925%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240925T232154Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D8caa7d04febf7940dbdb1fb1bac8b9fabf6a2a9380f94622bbb77581451faf88ba92b9e6c79683db3594c75c425fdb2b90b1366b9d2b2ecaa65a79fc5893d250f2e68e6e6b5d0e70927be89b970bb31c98e664d3f3f63dfff542948945b665f568edb4f2953f205bed420c86164f7ded5634498bda6c56be615a902a8fcbb3cb31fb2afc5e4cc02a3f371f1642dc4cebb8d962de9f361ea22e7a0b85f361a26fb81df035b8250808da560e6c042d7f51690ad7a2b3bfdbeeaeeaa52bdf5c092952a9b45f43a8068bc5c4f962f22d96a635f8409c31c975ccde462725b650a14929b5d3ebc331153029d8b3526329fc2667edaee03a664de4b675ff416d08debb'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "a0luUZ9DfdEM"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "z7qgTN5ufdEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/kaggle/input/gene-expression/data_set_ALL_AML_train.csv\")\n",
        "actual = pd.read_csv(\"/kaggle/input/gene-expression/actual.csv\")\n",
        "independent = pd.read_csv(\"/kaggle/input/gene-expression/data_set_ALL_AML_independent.csv\")\n",
        "train.head()"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "L6c2Io_IfdEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "iwKdnZCsfdEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "independent.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "VElsgrfyfdEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "metadata": {
        "trusted": true,
        "id": "mSbbaJRyfdEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "trusted": true,
        "id": "SySJrWV4fdEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we don't need call columns so let's remove them\n",
        "\n",
        "trainreq = [col for col in train.columns if \"call\" not in col]\n",
        "train = train[trainreq]\n",
        "train.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "dKjsK8JqfdEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.T\n",
        "train.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "VxpBMjeLfdEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2 = train.drop(['Gene Description','Gene Accession Number'],axis=0)\n",
        "train2.index = pd.to_numeric(train2.index)\n",
        "train2.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "r94KWS9tfdEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2.sort_index(inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6O3iAmBtfdEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "qATHjxnufdEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# There are two datasets containing the initial (training, 38 samples) and independent (test, 34 samples) datasets used in the paper. These datasets contain measurements corresponding to ALL and AML samples from Bone Marrow and Peripheral Blood. Intensity values have been re-scaled such that overall intensities for each chip are equivalent."
      ],
      "metadata": {
        "id": "Xtp19k68fdEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train2.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "Jo8Wc3gxfdEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual['cancer'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "MxWVtXTAfdE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patients = list(actual[:38]['cancer'])\n",
        "train2['Patient_Category'] = patients\n",
        "train2.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "SIMnuxmOfdE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2['Patient_Category'] = train2['Patient_Category'].replace({\"ALL\":0,\"AML\":1})\n",
        "train2.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "rLtl7kJ2fdE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train2.drop(\"Patient_Category\",axis=1)\n",
        "y = train2.Patient_Category"
      ],
      "metadata": {
        "trusted": true,
        "id": "yJXB20LkfdE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "PQqeZNcJfdE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "trusted": true,
        "id": "nYMhIe_efdE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "X_scl = sc.fit_transform(X)"
      ],
      "metadata": {
        "trusted": true,
        "id": "7EO7rTgJfdE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "q-791IiafdE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_components=30\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca = pca.fit_transform(X_scl)"
      ],
      "metadata": {
        "trusted": true,
        "id": "54skI3psfdE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xpcadf = pd.DataFrame(X_pca)\n",
        "Xpcadf.columns =['PC'+str(i) for i in range(1,n_components+1)]\n",
        "\n",
        "Xpcadf['Patient Category'] = patients\n",
        "print(f\"Percent of explained variance with {n_components} Components : \", round(pca.explained_variance_ratio_.sum()*100,2))\n",
        "Xpcadf.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "isUmYhxkfdE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "trusted": true,
        "id": "nzzIjQ2BfdE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,10))\n",
        "sns.set_style(\"darkgrid\")\n",
        "ax = sns.scatterplot(Xpcadf['PC1'],Xpcadf['PC2'],hue=Xpcadf['Patient Category'])\n",
        "\n",
        "plt.xlabel(f'PC1 ({round(pca.explained_variance_ratio_[0] * 100,1)} %)')\n",
        "plt.ylabel(f'PC2 ({round(pca.explained_variance_ratio_[1] * 100,1)} %)')\n",
        "plt.title('overall scatter plot of PC1 and PC2')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "rkNuCb0LfdE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter_3d(data_frame=Xpcadf,x='PC1',y='PC2',z='PC3',color='Patient Category',template='plotly_dark')\n",
        "fig.update_layout(title = \"3D Scatter plot for first 3 principal components\",title_x=0.5)\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "myTGmfDjfdE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variance = []\n",
        "comps = []\n",
        "for comp in range(2,31,1):\n",
        "    pca = PCA(n_components=comp)\n",
        "    imppca = pca.fit_transform(X_scl)\n",
        "    var = round(pca.explained_variance_ratio_.sum()*100,2)\n",
        "    variance.append(var)\n",
        "    comps.append(comp)\n",
        "\n",
        "pcatable = pd.DataFrame({\"Number of components\":comps,\"% of variance explained\":variance})\n",
        "pcatable.style.background_gradient(cmap=\"Reds\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "zw1OxFBqfdE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(data=pcatable,x='Number of components',y='% of variance explained',palette='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "AOlCdThmfdE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets find out which all features added the most to our PC1 and PC2"
      ],
      "metadata": {
        "id": "i_w85A20fdE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.head(2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "doOe_u31fdFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_importance_dataframe(pca, original_num_df):\n",
        "    importance_df  = pd.DataFrame(pca.components_)\n",
        "    importance_df.columns  = original_num_df.columns\n",
        "    importance_df =importance_df.apply(np.abs)\n",
        "    importance_df=importance_df.transpose()\n",
        "    num_pcs = importance_df.shape[1]\n",
        "    new_columns = [f'PC{i}' for i in range(1, num_pcs + 1)]\n",
        "    importance_df.columns  =new_columns\n",
        "    return importance_df\n",
        "\n",
        "importance_df  =create_importance_dataframe(pca,X)\n",
        "display(importance_df.head())"
      ],
      "metadata": {
        "trusted": true,
        "id": "FRvBCvrUfdFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc1_top_10_features = importance_df['PC1'].sort_values(ascending = False)[:10]\n",
        "print(), print(f'PC1 top 10 features are \\n')\n",
        "pd.DataFrame(pc1_top_10_features).reset_index().rename(columns={\"index\":\"Gene\",\"PC1\":\"Importance value for PC1\"})"
      ],
      "metadata": {
        "trusted": true,
        "id": "vYAJPbMyfdFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc2_top_10_features = importance_df['PC2'].sort_values(ascending = False)[:10]\n",
        "print(), print(f'PC2 top 10 features are \\n')\n",
        "pd.DataFrame(pc1_top_10_features).reset_index().rename(columns={\"index\":\"Gene\",\"PC2\":\"Importance value for PC2\"})"
      ],
      "metadata": {
        "trusted": true,
        "id": "txigcfL2fdFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "7nqwbKjKfdFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# let's try KMeans for some more intuition"
      ],
      "metadata": {
        "id": "ayETRxBPfdFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "sumofsq = {}\n",
        "for k in range(1,15):\n",
        "    km = KMeans(n_clusters=k,init='k-means++',max_iter=1000)\n",
        "    km = km.fit(X_scl)\n",
        "    sumofsq[k] = km.inertia_"
      ],
      "metadata": {
        "trusted": true,
        "id": "m8irIJllfdFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize=(14,8))\n",
        "plt.xlabel('Number of Clusters(k)')\n",
        "plt.ylabel('Sum of Square Distances')\n",
        "plt.title('Elbow Method For Optimal number of Clusters')\n",
        "sns.pointplot(x=list(sumofsq.keys()),y=list(sumofsq.values()),color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "s31ZQK6AfdFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# clusters = 3 seems fine !"
      ],
      "metadata": {
        "id": "IgyoVfatfdFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeansmodel = KMeans(n_clusters=3, init= 'k-means++', max_iter= 1000)\n",
        "kmeansmodel.fit_transform(X_scl)\n",
        "print()"
      ],
      "metadata": {
        "trusted": true,
        "id": "VJGllcrFfdFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Kmeansdf = X.copy()\n",
        "Kmeansdf['Cluster_by_KMeans'] = kmeansmodel.labels_"
      ],
      "metadata": {
        "trusted": true,
        "id": "6sa1GnkyfdFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xpcadf['Kmeans_cluster'] = kmeansmodel.labels_"
      ],
      "metadata": {
        "trusted": true,
        "id": "hs1enfCAfdFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.scatterplot(Xpcadf['PC1'],Xpcadf['PC2'],hue=Xpcadf['Kmeans_cluster'],palette=\"gist_rainbow\")\n",
        "\n",
        "plt.xlabel(f'PC1 ({round(pca.explained_variance_ratio_[0] * 100,1)} %)')\n",
        "plt.ylabel(f'PC2 ({round(pca.explained_variance_ratio_[1] * 100,1)} %)')\n",
        "plt.title('scatter plot of PC1 and PC2 with KMeans clusters')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "7Xc2MGKafdFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import matplotlib.cm as cm"
      ],
      "metadata": {
        "trusted": true,
        "id": "vAL5X2usfdFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range_n_clusters = [2, 3, 4, 5, 6,7,8,9,10]\n",
        "X = X_scl.copy()\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "    ax1.set_xlim([-0.1, 1])\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
        "    cluster_labels = clusterer.fit_predict(X)\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    print(\"For n_clusters =\", n_clusters,\"The average silhouette_score is :\", silhouette_avg)\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        ith_cluster_silhouette_values = \\\n",
        "            sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        y_lower = y_upper + 10\n",
        "\n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
        "                c=colors, edgecolor='k')\n",
        "\n",
        "    centers = clusterer.cluster_centers_\n",
        "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
        "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
        "                    s=50, edgecolor='k')\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                  \"with n_clusters = %d\" % n_clusters),\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Z0aJhFisfdFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From both Elbow method and silhouette analysis n_clusters = 3 seems fine !"
      ],
      "metadata": {
        "id": "DQIylyKzfdFh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "qegSIM_BfdFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "QeGQYJXrfdFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "uNI5tJlxfdFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "IVPRVhVAfdFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "CN7yoI4efdFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "_Ll3FkGUfdFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Lvx2FpS1fdFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "n8qM4YyFfdFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "4YnXGr0FfdFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "U5AazBPafdFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "lP6EvG1dfdFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "YMLGuz9IfdFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "7B5t9Jw0fdFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "UKEfPsNOfdFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "3oEJgto-fdFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "P540F3TffdFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "NQC1ntI0fdFx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}